{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install deep_translator transformers torch tensorflow seaborn matplotlib pandas numpy scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from deep_translator import GoogleTranslator  # Commented out backtranslation for now\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/combined_data.csv\", usecols=[\"Text\", \"Fraud level\"])\n",
        "df = df[df['Fraud level'].isin([0, 1])]\n",
        "\n",
        "# Split dataset (80% training, 20% test)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"Fraud level\"])\n",
        "\n",
        "\"\"\"\n",
        "# Back-translation function (commented out for now)\n",
        "def back_translate(text, src_lang=\"bn\", mid_lang=\"en\"):\n",
        "    try:\n",
        "        translated = GoogleTranslator(source=src_lang, target=mid_lang).translate(text)\n",
        "        back_translated = GoogleTranslator(source=mid_lang, target=src_lang).translate(translated)\n",
        "        return back_translated\n",
        "    except:\n",
        "        return text\n",
        "\n",
        "# Augment training data (commented out for now)\n",
        "back_translated_df = train_df.copy()\n",
        "back_translated_df[\"Text\"] = back_translated_df[\"Text\"].apply(lambda x: x + \" \" + back_translate(x))\n",
        "augmented_train_df = pd.concat([train_df, back_translated_df], ignore_index=True)\n",
        "\"\"\"\n",
        "\n",
        "# Use original training data without augmentation\n",
        "augmented_train_df = train_df.copy()\n",
        "\n",
        "# Reset indices\n",
        "augmented_train_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Prepare device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "# Custom Dataset for RoBERTa\n",
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Prepare datasets and dataloaders\n",
        "max_length = 128\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = FraudDataset(\n",
        "    augmented_train_df['Text'].values,\n",
        "    augmented_train_df['Fraud level'].values,\n",
        "    tokenizer,\n",
        "    max_length=max_length\n",
        ")\n",
        "test_dataset = FraudDataset(\n",
        "    test_df['Text'].values,\n",
        "    test_df['Fraud level'].values,\n",
        "    tokenizer,\n",
        "    max_length=max_length\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} | Loss: {total_loss/len(train_loader):.4f} | Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud (0)', 'Fraud (1)'], yticklabels=['Not Fraud (0)', 'Fraud (1)'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - RoBERTa')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b8B3Obhk89Lm",
        "outputId": "e6bfde1e-0b65-4fdd-8819-19c335f71868"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.7)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m537.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, deep_translator, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed deep_translator-1.11.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/combined_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1482700347>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/combined_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fraud level\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fraud level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/combined_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/combined_data.csv\", usecols=[\"Text\", \"Fraud level\"])\n",
        "df = df[df['Fraud level'].isin([0,1])]\n",
        "\n",
        "# Stratified train-test split (80-20)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Fraud level'])\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text,\n",
        "                                  max_length=self.max_length,\n",
        "                                  padding='max_length',\n",
        "                                  truncation=True,\n",
        "                                  return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "max_length = 128\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = FraudDataset(train_df['Text'].values, train_df['Fraud level'].values, tokenizer, max_length)\n",
        "test_dataset = FraudDataset(test_df['Text'].values, test_df['Fraud level'].values, tokenizer, max_length)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01, eps=1e-8)\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=int(0.1 * total_steps),\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "def train_epoch(model, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return total_loss / len(dataloader), correct / total\n",
        "\n",
        "def eval_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    return acc, all_labels, all_preds\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader)\n",
        "    test_acc, y_true, y_pred = eval_model(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Not Fraud (0)', 'Fraud (1)'],\n",
        "            yticklabels=['Not Fraud (0)', 'Fraud (1)'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vOxM9Tpp-sUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from deep_translator import GoogleTranslator\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import TrainerCallback\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load dataset\n",
        "try:\n",
        "    df = pd.read_csv(\"/content/combined_data.csv\", usecols=[\"Text\", \"Fraud level\"])\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: combined_data.csv not found.\")\n",
        "    exit(1)\n",
        "\n",
        "# Remove rows where 'Fraud level' is NaN or not in [0, 1]\n",
        "df = df[df['Fraud level'].isin([0, 1])]\n",
        "\n",
        "# Split dataset (80% training, 20% test)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"Fraud level\"])\n",
        "\n",
        "# Function for back translation (Bangla → English → Bangla)\n",
        "# def back_translate(text, src_lang=\"bn\", mid_lang=\"en\"):\n",
        "#     try:\n",
        "#         translated = GoogleTranslator(source=src_lang, target=mid_lang).translate(text)\n",
        "#         back_translated = GoogleTranslator(source=mid_lang, target=src_lang).translate(translated)\n",
        "#         return back_translated\n",
        "#     except Exception as e:\n",
        "#         print(f\"Translation error: {e}\")\n",
        "#         return text  # If translation fails, return original text\n",
        "\n",
        "# Create a new DataFrame with back-translated and concatenated text\n",
        "# back_translated_df = train_df.copy()\n",
        "# back_translated_df[\"Text\"] = back_translated_df[\"Text\"].apply(lambda x: x + \" \" + back_translate(x))\n",
        "\n",
        "# Concatenate original training set with back-translated set\n",
        "# augmented_train_df = pd.concat([train_df, back_translated_df], ignore_index=True)\n",
        "augmented_train_df = train_df.copy()  # Use original training data without back-translation\n",
        "\n",
        "# Display results\n",
        "print(\"Original Training Set Size:\", len(train_df))\n",
        "print(\"New Augmented Training Set Size:\", len(augmented_train_df))\n",
        "print(\"\\nSample of Augmented Training Set:\\n\", augmented_train_df.head(10))\n",
        "print(\"\\nTest Set (Unchanged):\\n\", test_df.head())\n",
        "print(\"\\nUnique Fraud Levels in Training Set:\", augmented_train_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Test Set:\", test_df['Fraud level'].unique())\n",
        "\n",
        "# Combine test and augmented training set for visualization\n",
        "df_combined = pd.concat([test_df, augmented_train_df])\n",
        "\n",
        "# Count fraud labels\n",
        "fraud_counts = df_combined['Fraud level'].value_counts()\n",
        "\n",
        "# Chart.js configuration for fraud label distribution\n",
        "print(\"\"\"\n",
        "```chartjs\n",
        "{\n",
        "  \"type\": \"bar\",\n",
        "  \"data\": {\n",
        "    \"labels\": [\"Not Fraud (0)\", \"Fraud (1)\"],\n",
        "    \"datasets\": [{\n",
        "      \"label\": \"Fraud Label Count\",\n",
        "      \"data\": [655, 634],\n",
        "      \"backgroundColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderWidth\": 1\n",
        "    }]\n",
        "  },\n",
        "  \"options\": {\n",
        "    \"scales\": {\n",
        "      \"y\": {\n",
        "        \"beginAtZero\": true,\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Count\"\n",
        "        }\n",
        "      },\n",
        "      \"x\": {\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Fraud Label\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"plugins\": {\n",
        "      \"title\": {\n",
        "        \"display\": true,\n",
        "        \"text\": \"Fraud Label Distribution in Test + Training Set\"\n",
        "      },\n",
        "      \"legend\": {\n",
        "        \"display\": false\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\"\"\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset Description:\")\n",
        "print(df.describe())\n",
        "print(\"\\nFirst 5 Rows of Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Text preprocessing functions\n",
        "def replace_strings(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\u00C0-\\u017F\"\n",
        "                               u\"\\u2000-\\u206F\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    # Keep English and numbers for mixed-language text\n",
        "    return text\n",
        "\n",
        "def remove_punctuations(my_str):\n",
        "    punctuations = '''````£|¢|Ñ+-*/=EROero৳০১২৩৪৫৬৭৮৯012–34567•89।!()-[]{};:'\"“\\’,<>./?@#$%^&*_~‘—॥”‰⚽️✌ ￰৷￰'''\n",
        "    no_punct = \"\"\n",
        "    for char in my_str:\n",
        "        if char not in punctuations:\n",
        "            no_punct += char\n",
        "    return no_punct\n",
        "\n",
        "def preprocessing(text):\n",
        "    out = remove_punctuations(replace_strings(text))\n",
        "    return out\n",
        "\n",
        "# Apply preprocessing once\n",
        "augmented_train_df['Text'] = augmented_train_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "test_df['Text'] = test_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "\n",
        "# Reset indices\n",
        "augmented_train_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Prepare training and testing data\n",
        "train_texts = augmented_train_df['Text'].values\n",
        "train_labels = augmented_train_df['Fraud level'].values.astype(int)\n",
        "test_texts = test_df['Text'].values\n",
        "test_labels = test_df['Fraud level'].values.astype(int)\n",
        "\n",
        "# Initialize XLM-RoBERTa tokenizer\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(texts, max_length=128):\n",
        "    encodings = tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return encodings\n",
        "\n",
        "train_encodings = tokenize_data(train_texts)\n",
        "test_encodings = tokenize_data(test_texts)\n",
        "\n",
        "# Create custom dataset class\n",
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = FraudDataset(train_encodings, train_labels)\n",
        "test_dataset = FraudDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize XLM-RoBERTa model\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)\n",
        "\n",
        "# Custom callback to log loss and accuracy\n",
        "class CustomCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.train_loss = []\n",
        "        self.eval_loss = []\n",
        "        self.eval_acc = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs.get('loss') is not None:\n",
        "            self.train_loss.append(logs['loss'])\n",
        "        if logs.get('eval_loss') is not None:\n",
        "            self.eval_loss.append(logs['eval_loss'])\n",
        "        if logs.get('eval_accuracy') is not None:\n",
        "            self.eval_acc.append(logs['eval_accuracy'])\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.train_loss, label='Train Loss')\n",
        "        plt.plot(self.eval_loss, label='Validation Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Logging Step')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.eval_acc, label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "custom_callback = CustomCallback()\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to=\"none\"  # Disable W&B logging\n",
        ")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[custom_callback]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate model\n",
        "results = trainer.evaluate()\n",
        "print(\"Test Accuracy:\", results['eval_accuracy'])\n",
        "\n",
        "# Plot loss and accuracy\n",
        "custom_callback.plot_metrics()\n",
        "\n",
        "# Generate predictions for confusion matrix\n",
        "predictions = trainer.predict(test_dataset)\n",
        "pred_labels = predictions.predictions.argmax(-1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud (0)', 'Fraud (1)'], yticklabels=['Not Fraud (0)', 'Fraud (1)'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for XLM-RoBERTa Classification')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J65ecPl2F4JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from deep_translator import GoogleTranslator\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import TrainerCallback\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Load dataset\n",
        "try:\n",
        "    df = pd.read_csv(\"/content/combined_data.csv\", usecols=[\"Text\", \"Fraud level\"])\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: combined_data.csv not found.\")\n",
        "    exit(1)\n",
        "\n",
        "# Remove rows where 'Fraud level' is NaN or not in [0, 1]\n",
        "df = df[df['Fraud level'].isin([0, 1])]\n",
        "\n",
        "# Split dataset: 70% train, 10% validation, 20% test\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"Fraud level\"])\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.125, random_state=42, stratify=train_val_df[\"Fraud level\"])  # 10% of 80% = 12.5% of train_val\n",
        "\n",
        "# Function for back translation (Bangla → English → Bangla) without API key\n",
        "def back_translate(text, src_lang=\"bn\", mid_lang=\"en\"):\n",
        "    try:\n",
        "        translator = GoogleTranslator(source=src_lang, target=mid_lang)\n",
        "        translated = translator.translate(text)\n",
        "        back_translator = GoogleTranslator(source=mid_lang, target=src_lang)\n",
        "        back_translated = back_translator.translate(translated)\n",
        "        return back_translated\n",
        "    except Exception as e:\n",
        "        print(f\"Translation error: {e}\")\n",
        "        return text  # If translation fails, return original text\n",
        "\n",
        "# Create a new DataFrame with back-translated and concatenated text for training set\n",
        "back_translated_df = train_df.copy()\n",
        "back_translated_df[\"Text\"] = back_translated_df[\"Text\"].apply(lambda x: x + \" \" + back_translate(x))\n",
        "\n",
        "# Concatenate original training set with back-translated set\n",
        "augmented_train_df = pd.concat([train_df, back_translated_df], ignore_index=True)\n",
        "\n",
        "# Display results\n",
        "print(\"Original Training Set Size:\", len(train_df))\n",
        "print(\"Augmented Training Set Size:\", len(augmented_train_df))\n",
        "print(\"Validation Set Size:\", len(val_df))\n",
        "print(\"Test Set Size:\", len(test_df))\n",
        "print(\"\\nSample of Augmented Training Set:\\n\", augmented_train_df.head(10))\n",
        "print(\"\\nValidation Set:\\n\", val_df.head())\n",
        "print(\"\\nTest Set:\\n\", test_df.head())\n",
        "print(\"\\nUnique Fraud Levels in Training Set:\", augmented_train_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Validation Set:\", val_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Test Set:\", test_df['Fraud level'].unique())\n",
        "\n",
        "# Combine test, validation, and augmented training set for visualization\n",
        "df_combined = pd.concat([test_df, val_df, augmented_train_df])\n",
        "\n",
        "# Count fraud labels\n",
        "fraud_counts = df_combined['Fraud level'].value_counts()\n",
        "\n",
        "# Chart.js configuration for fraud label distribution\n",
        "print(\"\"\"\n",
        "```chartjs\n",
        "{\n",
        "  \"type\": \"bar\",\n",
        "  \"data\": {\n",
        "    \"labels\": [\"Not Fraud (0)\", \"Fraud (1)\"],\n",
        "    \"datasets\": [{\n",
        "      \"label\": \"Fraud Label Count\",\n",
        "      \"data\": [\"\"\" + str(fraud_counts.get(0, 0)) + \"\"\", \"\"\" + str(fraud_counts.get(1, 0)) + \"\"\"],\n",
        "      \"backgroundColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderWidth\": 1\n",
        "    }]\n",
        "  },\n",
        "  \"options\": {\n",
        "    \"scales\": {\n",
        "      \"y\": {\n",
        "        \"beginAtZero\": true,\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Count\"\n",
        "        }\n",
        "      },\n",
        "      \"x\": {\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Fraud Label\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"plugins\": {\n",
        "      \"title\": {\n",
        "        \"display\": true,\n",
        "        \"text\": \"Fraud Label Distribution in Test + Validation + Training Set\"\n",
        "      },\n",
        "      \"legend\": {\n",
        "        \"display\": false\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\"\"\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset Description:\")\n",
        "print(df.describe())\n",
        "print(\"\\nFirst 5 Rows of Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Text preprocessing functions\n",
        "def replace_strings(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\u00C0-\\u017F\"\n",
        "                               u\"\\u2000-\\u206F\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    # Keep English and numbers for mixed-language text\n",
        "    return text\n",
        "\n",
        "def remove_punctuations(my_str):\n",
        "    punctuations = '''````£|¢|Ñ+-*/=EROero৳০১২৩৪৫৬৭৮৯012–34567•89।!()-[]{};:'\"“\\’,<>./?@#$%^&*_~‘—॥”‰⚽️✌ ￰৷￰'''\n",
        "    no_punct = \"\"\n",
        "    for char in my_str:\n",
        "        if char not in punctuations:\n",
        "            no_punct += char\n",
        "    return no_punct\n",
        "\n",
        "def preprocessing(text):\n",
        "    out = remove_punctuations(replace_strings(text))\n",
        "    return out\n",
        "\n",
        "# Apply preprocessing once\n",
        "augmented_train_df['Text'] = augmented_train_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "val_df['Text'] = val_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "test_df['Text'] = test_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "\n",
        "# Reset indices\n",
        "augmented_train_df.reset_index(drop=True, inplace=True)\n",
        "val_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Prepare training, validation, and testing data\n",
        "train_texts = augmented_train_df['Text'].values\n",
        "train_labels = augmented_train_df['Fraud level'].values.astype(int)\n",
        "val_texts = val_df['Text'].values\n",
        "val_labels = val_df['Fraud level'].values.astype(int)\n",
        "test_texts = test_df['Text'].values\n",
        "test_labels = test_df['Fraud level'].values.astype(int)\n",
        "\n",
        "# Initialize XLM-RoBERTa tokenizer\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(texts, max_length=128):\n",
        "    encodings = tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return encodings\n",
        "\n",
        "train_encodings = tokenize_data(train_texts)\n",
        "val_encodings = tokenize_data(val_texts)\n",
        "test_encodings = tokenize_data(test_texts)\n",
        "\n",
        "# Create custom dataset class\n",
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = FraudDataset(train_encodings, train_labels)\n",
        "val_dataset = FraudDataset(val_encodings, val_labels)\n",
        "test_dataset = FraudDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize XLM-RoBERTa model\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)\n",
        "\n",
        "# Custom callback to log loss and accuracy\n",
        "class CustomCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.train_loss = []\n",
        "        self.eval_loss = []\n",
        "        self.eval_acc = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs.get('loss') is not None:\n",
        "            self.train_loss.append(logs['loss'])\n",
        "        if logs.get('eval_loss') is not None:\n",
        "            self.eval_loss.append(logs['eval_loss'])\n",
        "        if logs.get('eval_accuracy') is not None:\n",
        "            self.eval_acc.append(logs['eval_accuracy'])\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.train_loss, label='Train Loss')\n",
        "        plt.plot(self.eval_loss, label='Validation Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Logging Step')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.eval_acc, label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "custom_callback = CustomCallback()\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,  # Increased to reduce log verbosity\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to=\"none\"  # Disable W&B logging\n",
        ")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,  # Use validation set for evaluation\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[custom_callback]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate model on test set\n",
        "results = trainer.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {results['eval_accuracy']}\")\n",
        "\n",
        "# Plot loss and accuracy\n",
        "custom_callback.plot_metrics()\n",
        "\n",
        "# Generate predictions for confusion matrix on test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "pred_labels = predictions.predictions.argmax(-1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud (0)', 'Fraud (1)'], yticklabels=['Not Fraud (0)', 'Fraud (1)'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for XLM-RoBERTa Classification')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s3OHVKsgHrCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import TrainerCallback\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Display results\n",
        "print(\"Original Training Set Size:\", len(train_df))\n",
        "print(\"Augmented Training Set Size:\", len(augmented_train_df))\n",
        "print(\"Validation Set Size:\", len(val_df))\n",
        "print(\"Test Set Size:\", len(test_df))\n",
        "print(\"\\nSample of Augmented Training Set:\\n\", augmented_train_df.head(10))\n",
        "print(\"\\nValidation Set:\\n\", val_df.head())\n",
        "print(\"\\nTest Set:\\n\", test_df.head())\n",
        "print(\"\\nUnique Fraud Levels in Training Set:\", augmented_train_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Validation Set:\", val_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Test Set:\", test_df['Fraud level'].unique())\n",
        "\n",
        "# Combine test, validation, and augmented training set for visualization\n",
        "df_combined = pd.concat([test_df, val_df, augmented_train_df])\n",
        "\n",
        "# Count fraud labels\n",
        "fraud_counts = df_combined['Fraud level'].value_counts()\n",
        "\n",
        "# Chart.js configuration for fraud label distribution\n",
        "print(\"\"\"\n",
        "```chartjs\n",
        "{\n",
        "  \"type\": \"bar\",\n",
        "  \"data\": {\n",
        "    \"labels\": [\"Not Fraud (0)\", \"Fraud (1)\"],\n",
        "    \"datasets\": [{\n",
        "      \"label\": \"Fraud Label Count\",\n",
        "      \"data\": [\"\"\" + str(fraud_counts.get(0, 0)) + \"\"\", \"\"\" + str(fraud_counts.get(1, 0)) + \"\"\"],\n",
        "      \"backgroundColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderWidth\": 1\n",
        "    }]\n",
        "  },\n",
        "  \"options\": {\n",
        "    \"scales\": {\n",
        "      \"y\": {\n",
        "        \"beginAtZero\": true,\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Count\"\n",
        "        }\n",
        "      },\n",
        "      \"x\": {\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Fraud Label\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"plugins\": {\n",
        "      \"title\": {\n",
        "        \"display\": true,\n",
        "        \"text\": \"Fraud Label Distribution in Test + Validation + Training Set\"\n",
        "      },\n",
        "      \"legend\": {\n",
        "        \"display\": false\n",
        "      }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\"\"\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset Description:\")\n",
        "print(df.describe())\n",
        "print(\"\\nFirst 5 Rows of Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Text preprocessing functions\n",
        "def replace_strings(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\u00C0-\\u017F\"\n",
        "                               u\"\\u2000-\\u206F\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    return text\n",
        "\n",
        "def preprocessing(text):\n",
        "    return replace_strings(text)  # Only remove emojis, keep punctuations\n",
        "\n",
        "# Apply preprocessing\n",
        "augmented_train_df['Text'] = augmented_train_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "val_df['Text'] = val_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "test_df['Text'] = test_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "\n",
        "# Reset indices\n",
        "augmented_train_df.reset_index(drop=True, inplace=True)\n",
        "val_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Prepare training, validation, and testing data\n",
        "train_texts = augmented_train_df['Text'].values\n",
        "train_labels = augmented_train_df['Fraud level'].values.astype(int)\n",
        "val_texts = val_df['Text'].values\n",
        "val_labels = val_df['Fraud level'].values.astype(int)\n",
        "test_texts = test_df['Text'].values\n",
        "test_labels = test_df['Fraud level'].values.astype(int)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "# Initialize XLM-RoBERTa tokenizer\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(texts, max_length=256):  # Increased max_length\n",
        "    encodings = tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return encodings\n",
        "\n",
        "train_encodings = tokenize_data(train_texts)\n",
        "val_encodings = tokenize_data(val_texts)\n",
        "test_encodings = tokenize_data(test_texts)\n",
        "\n",
        "# Create custom dataset class\n",
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = FraudDataset(train_encodings, train_labels)\n",
        "val_dataset = FraudDataset(val_encodings, val_labels)\n",
        "test_dataset = FraudDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize XLM-RoBERTa model with dropout\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)\n",
        "model.config.hidden_dropout_prob = 0.3  # Added dropout\n",
        "\n",
        "# Custom trainer to apply class weights\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Custom callback to log loss and accuracy\n",
        "class CustomCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.train_loss = []\n",
        "        self.eval_loss = []\n",
        "        self.eval_acc = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs.get('loss') is not None:\n",
        "            self.train_loss.append(logs['loss'])\n",
        "        if logs.get('eval_loss') is not None:\n",
        "            self.eval_loss.append(logs['eval_loss'])\n",
        "        if logs.get('eval_accuracy') is not None:\n",
        "            self.eval_acc.append(logs['eval_accuracy'])\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.train_loss, label='Train Loss')\n",
        "        plt.plot(self.eval_loss, label='Validation Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Logging Step')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.eval_acc, label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "custom_callback = CustomCallback()\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,  # Increased epochs\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=2e-5,  # Standard for Transformers\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.1,  # Increased regularization\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to=\"none\"  # Disable W&B\n",
        ")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    report = classification_report(labels, preds, output_dict=True)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision_0\": report['0']['precision'],\n",
        "        \"recall_0\": report['0']['recall'],\n",
        "        \"f1_0\": report['0']['f1-score'],\n",
        "        \"precision_1\": report['1']['precision'],\n",
        "        \"recall_1\": report['1']['recall'],\n",
        "        \"f1_1\": report['1']['f1-score']\n",
        "    }\n",
        "\n",
        "# Initialize CustomTrainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[custom_callback]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_results = trainer.evaluate(val_dataset)\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"Accuracy: {val_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {val_results['eval_precision_0']:.4f}, Recall: {val_results['eval_recall_0']:.4f}, F1: {val_results['eval_f1_0']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {val_results['eval_precision_1']:.4f}, Recall: {val_results['eval_recall_1']:.4f}, F1: {val_results['eval_f1_1']:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {test_results['eval_precision_0']:.4f}, Recall: {test_results['eval_recall_0']:.4f}, F1: {test_results['eval_f1_0']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {test_results['eval_precision_1']:.4f}, Recall: {test_results['eval_recall_1']:.4f}, F1: {test_results['eval_f1_1']:.4f}\")\n",
        "\n",
        "# Plot loss and accuracy\n",
        "custom_callback.plot_metrics()\n",
        "\n",
        "# Generate predictions for confusion matrix on test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "pred_labels = predictions.predictions.argmax(-1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "# Print prediction distribution\n",
        "print(\"\\nPrediction Distribution on Test Set:\")\n",
        "print(pd.Series(pred_labels).value_counts())\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud (0)', 'Fraud (1)'], yticklabels=['Not Fraud (0)', 'Fraud (1)'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for XLM-RoBERTa Classification')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(true_labels, pred_labels, target_names=['Not Fraud (0)', 'Fraud (1)']))"
      ],
      "metadata": {
        "id": "77DZR46VTp1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gpTEt0uOzOa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import TrainerCallback\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Display results\n",
        "print(\"Original Training Set Size:\", len(train_df))\n",
        "print(\"Augmented Training Set Size:\", len(augmented_train_df))\n",
        "print(\"Validation Set Size:\", len(val_df))\n",
        "print(\"Test Set Size:\", len(test_df))\n",
        "print(\"\\nSample of Augmented Training Set:\\n\", augmented_train_df.head(10))\n",
        "print(\"\\nValidation Set:\\n\", val_df.head())\n",
        "print(\"\\nTest Set:\\n\", test_df.head())\n",
        "print(\"\\nUnique Fraud Levels in Training Set:\", augmented_train_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Validation Set:\", val_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Test Set:\", test_df['Fraud level'].unique())\n",
        "\n",
        "# Combine test, validation, and augmented training set for visualization\n",
        "df_combined = pd.concat([test_df, val_df, augmented_train_df])\n",
        "\n",
        "# Count fraud labels\n",
        "fraud_counts = df_combined['Fraud level'].value_counts()\n",
        "\n",
        "# Chart.js configuration for fraud label distribution\n",
        "print(\"\"\"\n",
        "```chartjs\n",
        "{\n",
        "  \"type\": \"bar\",\n",
        "  \"data\": {\n",
        "    \"labels\": [\"Not Fraud (0)\", \"Fraud (1)\"],\n",
        "    \"datasets\": [{\n",
        "      \"label\": \"Fraud Label Count\",\n",
        "      \"data\": [\"\"\" + str(fraud_counts.get(0, 0)) + \"\"\", \"\"\" + str(fraud_counts.get(1, 0)) + \"\"\"],\n",
        "      \"backgroundColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderWidth\": 1\n",
        "    }]\n",
        "  },\n",
        "  \"options\": {\n",
        "    \"scales\": {\n",
        "      \"y\": {\n",
        "        \"beginAtZero\": true,\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Count\"\n",
        "        }\n",
        "      },\n",
        "      \"x\": {\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Fraud Label\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"plugins\": {\n",
        "      \"title\": {\n",
        "        \"display\": true,\n",
        "        \"text\": \"Fraud Label Distribution in Test + Validation + Training Set\"\n",
        "      },\n",
        "      \"legend\": {\n",
        "        \"display\": false\n",
        "      }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\"\"\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset Description:\")\n",
        "print(df.describe())\n",
        "print(\"\\nFirst 5 Rows of Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Text preprocessing functions\n",
        "def replace_strings(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\u00C0-\\u017F\"\n",
        "                               u\"\\u2000-\\u206F\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    return text\n",
        "\n",
        "def preprocessing(text):\n",
        "    return replace_strings(text)  # Only remove emojis, keep punctuations\n",
        "\n",
        "# Apply preprocessing\n",
        "augmented_train_df['Text'] = augmented_train_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "val_df['Text'] = val_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "test_df['Text'] = test_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "\n",
        "# Reset indices\n",
        "augmented_train_df.reset_index(drop=True, inplace=True)\n",
        "val_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Prepare training, validation, and testing data\n",
        "train_texts = augmented_train_df['Text'].values\n",
        "train_labels = augmented_train_df['Fraud level'].values.astype(int)\n",
        "val_texts = val_df['Text'].values\n",
        "val_labels = val_df['Fraud level'].values.astype(int)\n",
        "test_texts = test_df['Text'].values\n",
        "test_labels = test_df['Fraud level'].values.astype(int)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "# Initialize BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(texts, max_length=256):  # Increased max_length\n",
        "    encodings = tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return encodings\n",
        "\n",
        "train_encodings = tokenize_data(train_texts)\n",
        "val_encodings = tokenize_data(val_texts)\n",
        "test_encodings = tokenize_data(test_texts)\n",
        "\n",
        "# Create custom dataset class\n",
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = FraudDataset(train_encodings, train_labels)\n",
        "val_dataset = FraudDataset(val_encodings, val_labels)\n",
        "test_dataset = FraudDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize BERT model with dropout\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model.config.hidden_dropout_prob = 0.3  # Added dropout\n",
        "\n",
        "# Custom trainer to apply class weights\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Custom callback to log loss and accuracy\n",
        "class CustomCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.train_loss = []\n",
        "        self.eval_loss = []\n",
        "        self.eval_acc = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs.get('loss') is not None:\n",
        "            self.train_loss.append(logs['loss'])\n",
        "        if logs.get('eval_loss') is not None:\n",
        "            self.eval_loss.append(logs['eval_loss'])\n",
        "        if logs.get('eval_accuracy') is not None:\n",
        "            self.eval_acc.append(logs['eval_accuracy'])\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.train_loss, label='Train Loss')\n",
        "        plt.plot(self.eval_loss, label='Validation Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Logging Step')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.eval_acc, label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "custom_callback = CustomCallback()\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    report = classification_report(labels, preds, output_dict=True)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision_0\": report['0']['precision'],\n",
        "        \"recall_0\": report['0']['recall'],\n",
        "        \"f1_0\": report['0']['f1-score'],\n",
        "        \"precision_1\": report['1']['precision'],\n",
        "        \"recall_1\": report['1']['recall'],\n",
        "        \"f1_1\": report['1']['f1-score']\n",
        "    }\n",
        "\n",
        "# Initialize CustomTrainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[custom_callback]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_results = trainer.evaluate(val_dataset)\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"Accuracy: {val_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {val_results['eval_precision_0']:.4f}, Recall: {val_results['eval_recall_0']:.4f}, F1: {val_results['eval_f1_0']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {val_results['eval_precision_1']:.4f}, Recall: {val_results['eval_recall_1']:.4f}, F1: {val_results['eval_f1_1']:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {test_results['eval_precision_0']:.4f}, Recall: {test_results['eval_recall_0']:.4f}, F1: {test_results['eval_f1_0']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {test_results['eval_precision_1']:.4f}, Recall: {test_results['eval_recall_1']:.4f}, F1: {test_results['eval_f1_1']:.4f}\")\n",
        "\n",
        "# Plot loss and accuracy\n",
        "custom_callback.plot_metrics()\n",
        "\n",
        "# Generate predictions for confusion matrix on test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "pred_labels = predictions.predictions.argmax(-1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "# Print prediction distribution\n",
        "print(\"\\nPrediction Distribution on Test Set:\")\n",
        "print(pd.Series(pred_labels).value_counts())\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud (0)', 'Fraud (1)'], yticklabels=['Not Fraud (0)', 'Fraud (1)'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for BERT Classification')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(true_labels, pred_labels, target_names=['Not Fraud (0)', 'Fraud (1)']))"
      ],
      "metadata": {
        "id": "YJtjUK9koSzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import TrainerCallback\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Display results\n",
        "print(\"Original Training Set Size:\", len(train_df))\n",
        "print(\"Augmented Training Set Size:\", len(augmented_train_df))\n",
        "print(\"Validation Set Size:\", len(val_df))\n",
        "print(\"Test Set Size:\", len(test_df))\n",
        "print(\"\\nSample of Augmented Training Set:\\n\", augmented_train_df.head(10))\n",
        "print(\"\\nValidation Set:\\n\", val_df.head())\n",
        "print(\"\\nTest Set:\\n\", test_df.head())\n",
        "print(\"\\nUnique Fraud Levels in Training Set:\", augmented_train_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Validation Set:\", val_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Test Set:\", test_df['Fraud level'].unique())\n",
        "\n",
        "# Combine test, validation, and augmented training set for visualization\n",
        "df_combined = pd.concat([test_df, val_df, augmented_train_df])\n",
        "\n",
        "# Count fraud labels\n",
        "fraud_counts = df_combined['Fraud level'].value_counts()\n",
        "\n",
        "# Chart.js configuration for fraud label distribution\n",
        "print(\"\"\"\n",
        "```chartjs\n",
        "{\n",
        "  \"type\": \"bar\",\n",
        "  \"data\": {\n",
        "    \"labels\": [\"Not Fraud (0)\", \"Fraud (1)\"],\n",
        "    \"datasets\": [{\n",
        "      \"label\": \"Fraud Label Count\",\n",
        "      \"data\": [\"\"\" + str(fraud_counts.get(0, 0)) + \"\"\", \"\"\" + str(fraud_counts.get(1, 0)) + \"\"\"],\n",
        "      \"backgroundColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderWidth\": 1\n",
        "    }]\n",
        "  },\n",
        "  \"options\": {\n",
        "    \"scales\": {\n",
        "      \"y\": {\n",
        "        \"beginAtZero\": true,\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Count\"\n",
        "        }\n",
        "      },\n",
        "      \"x\": {\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Fraud Label\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"plugins\": {\n",
        "      \"title\": {\n",
        "        \"display\": true,\n",
        "        \"text\": \"Fraud Label Distribution in Test + Validation + Training Set\"\n",
        "      },\n",
        "      \"legend\": {\n",
        "        \"display\": false\n",
        "      }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\"\"\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset Description:\")\n",
        "print(df.describe())\n",
        "print(\"\\nFirst 5 Rows of Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Text preprocessing functions\n",
        "def replace_strings(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\u00C0-\\u017F\"\n",
        "                               u\"\\u2000-\\u206F\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    return text\n",
        "\n",
        "def preprocessing(text):\n",
        "    return replace_strings(text)  # Only remove emojis, keep punctuations\n",
        "\n",
        "# Apply preprocessing\n",
        "augmented_train_df['Text'] = augmented_train_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "val_df['Text'] = val_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "test_df['Text'] = test_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "\n",
        "# Reset indices\n",
        "augmented_train_df.reset_index(drop=True, inplace=True)\n",
        "val_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Prepare training, validation, and testing data\n",
        "train_texts = augmented_train_df['Text'].values\n",
        "train_labels = augmented_train_df['Fraud level'].values.astype(int)\n",
        "val_texts = val_df['Text'].values\n",
        "val_labels = val_df['Fraud level'].values.astype(int)\n",
        "test_texts = test_df['Text'].values\n",
        "test_labels = test_df['Fraud level'].values.astype(int)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "# Initialize mBERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(texts, max_length=256):  # Increased max_length\n",
        "    encodings = tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return encodings\n",
        "\n",
        "train_encodings = tokenize_data(train_texts)\n",
        "val_encodings = tokenize_data(val_texts)\n",
        "test_encodings = tokenize_data(test_texts)\n",
        "\n",
        "# Create custom dataset class\n",
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = FraudDataset(train_encodings, train_labels)\n",
        "val_dataset = FraudDataset(val_encodings, val_labels)\n",
        "test_dataset = FraudDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize mBERT model with dropout\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased', num_labels=2)\n",
        "model.config.hidden_dropout_prob = 0.3  # Added dropout\n",
        "\n",
        "# Custom trainer to apply class weights\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Custom callback to log loss and accuracy\n",
        "class CustomCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.train_loss = []\n",
        "        self.eval_loss = []\n",
        "        self.eval_acc = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs.get('loss') is not None:\n",
        "            self.train_loss.append(logs['loss'])\n",
        "        if logs.get('eval_loss') is not None:\n",
        "            self.eval_loss.append(logs['eval_loss'])\n",
        "        if logs.get('eval_accuracy') is not None:\n",
        "            self.eval_acc.append(logs['eval_accuracy'])\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.train_loss, label='Train Loss')\n",
        "        plt.plot(self.eval_loss, label='Validation Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Logging Step')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.eval_acc, label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "custom_callback = CustomCallback()\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    report = classification_report(labels, preds, output_dict=True)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision_0\": report['0']['precision'],\n",
        "        \"recall_0\": report['0']['recall'],\n",
        "        \"f1_0\": report['0']['f1-score'],\n",
        "        \"precision_1\": report['1']['precision'],\n",
        "        \"recall_1\": report['1']['recall'],\n",
        "        \"f1_1\": report['1']['f1-score']\n",
        "    }\n",
        "\n",
        "# Initialize CustomTrainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[custom_callback]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_results = trainer.evaluate(val_dataset)\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"Accuracy: {val_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {val_results['eval_precision_0']:.4f}, Recall: {val_results['eval_recall_0']:.4f}, F1: {val_results['eval_f1_0']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {val_results['eval_precision_1']:.4f}, Recall: {val_results['eval_recall_1']:.4f}, F1: {val_results['eval_f1_1']:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {test_results['eval_precision_0']:.4f}, Recall: {test_results['eval_recall_0']:.4f}, F1: {test_results['eval_f1_0']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {test_results['eval_precision_1']:.4f}, Recall: {test_results['eval_recall_1']:.4f}, F1: {test_results['eval_f1_1']:.4f}\")\n",
        "\n",
        "# Plot loss and accuracy\n",
        "custom_callback.plot_metrics()\n",
        "\n",
        "# Generate predictions for confusion matrix on test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "pred_labels = predictions.predictions.argmax(-1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "# Print prediction distribution\n",
        "print(\"\\nPrediction Distribution on Test Set:\")\n",
        "print(pd.Series(pred_labels).value_counts())\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud (0)', 'Fraud (1)'], yticklabels=['Not Fraud (0)', 'Fraud (1)'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for mBERT Classification')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(true_labels, pred_labels, target_names=['Not Fraud (0)', 'Fraud (1)']))"
      ],
      "metadata": {
        "id": "5Wx8zuSQqAsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from transformers import ElectraTokenizer, ElectraForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import TrainerCallback\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Display results\n",
        "print(\"Original Training Set Size:\", len(train_df))\n",
        "print(\"Augmented Training Set Size:\", len(augmented_train_df))\n",
        "print(\"Validation Set Size:\", len(val_df))\n",
        "print(\"Test Set Size:\", len(test_df))\n",
        "print(\"\\nSample of Augmented Training Set:\\n\", augmented_train_df.head(10))\n",
        "print(\"\\nValidation Set:\\n\", val_df.head())\n",
        "print(\"\\nTest Set:\\n\", test_df.head())\n",
        "print(\"\\nUnique Fraud Levels in Training Set:\", augmented_train_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Validation Set:\", val_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Test Set:\", test_df['Fraud level'].unique())\n",
        "\n",
        "# Combine test, validation, and augmented training set for visualization\n",
        "df_combined = pd.concat([test_df, val_df, augmented_train_df])\n",
        "\n",
        "# Count fraud labels\n",
        "fraud_counts = df_combined['Fraud level'].value_counts()\n",
        "\n",
        "# Chart.js configuration for fraud label distribution\n",
        "print(\"\"\"\n",
        "```chartjs\n",
        "{\n",
        "  \"type\": \"bar\",\n",
        "  \"data\": {\n",
        "    \"labels\": [\"Not Fraud (0)\", \"Fraud (1)\"],\n",
        "    \"datasets\": [{\n",
        "      \"label\": \"Fraud Label Count\",\n",
        "      \"data\": [\"\"\" + str(fraud_counts.get(0, 0)) + \"\"\", \"\"\" + str(fraud_counts.get(1, 0)) + \"\"\"],\n",
        "      \"backgroundColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderWidth\": 1\n",
        "    }]\n",
        "  },\n",
        "  \"options\": {\n",
        "    \"scales\": {\n",
        "      \"y\": {\n",
        "        \"beginAtZero\": true,\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Count\"\n",
        "        }\n",
        "      },\n",
        "      \"x\": {\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Fraud Label\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"plugins\": {\n",
        "      \"title\": {\n",
        "        \"display\": true,\n",
        "        \"text\": \"Fraud Label Distribution in Test + Validation + Training Set\"\n",
        "      },\n",
        "      \"legend\": {\n",
        "        \"display\": false\n",
        "      }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\"\"\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset Description:\")\n",
        "print(df.describe())\n",
        "print(\"\\nFirst 5 Rows of Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Text preprocessing functions\n",
        "def replace_strings(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\u00C0-\\u017F\"\n",
        "                               u\"\\u2000-\\u206F\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    return text\n",
        "\n",
        "def preprocessing(text):\n",
        "    return replace_strings(text)  # Only remove emojis, keep punctuations\n",
        "\n",
        "# Apply preprocessing\n",
        "augmented_train_df['Text'] = augmented_train_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "val_df['Text'] = val_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "test_df['Text'] = test_df['Text'].apply(lambda x: preprocessing(str(x)))\n",
        "\n",
        "# Reset indices\n",
        "augmented_train_df.reset_index(drop=True, inplace=True)\n",
        "val_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Prepare training, validation, and testing data\n",
        "train_texts = augmented_train_df['Text'].values\n",
        "train_labels = augmented_train_df['Fraud level'].values.astype(int)\n",
        "val_texts = val_df['Text'].values\n",
        "val_labels = val_df['Fraud level'].values.astype(int)\n",
        "test_texts = test_df['Text'].values\n",
        "test_labels = test_df['Fraud level'].values.astype(int)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "# Initialize Bangla BERT tokenizer\n",
        "tokenizer = ElectraTokenizer.from_pretrained('csebuetnlp/banglabert')\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(texts, max_length=256):  # Increased max_length\n",
        "    encodings = tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return encodings\n",
        "\n",
        "train_encodings = tokenize_data(train_texts)\n",
        "val_encodings = tokenize_data(val_texts)\n",
        "test_encodings = tokenize_data(test_texts)\n",
        "\n",
        "# Create custom dataset class\n",
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = FraudDataset(train_encodings, train_labels)\n",
        "val_dataset = FraudDataset(val_encodings, val_labels)\n",
        "test_dataset = FraudDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize Bangla BERT model with dropout\n",
        "model = ElectraForSequenceClassification.from_pretrained('csebuetnlp/banglabert', num_labels=2)\n",
        "model.config.hidden_dropout_prob = 0.3  # Added dropout\n",
        "\n",
        "# Custom trainer to apply class weights\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Custom callback to log loss and accuracy\n",
        "class CustomCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.train_loss = []\n",
        "        self.eval_loss = []\n",
        "        self.eval_acc = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs.get('loss') is not None:\n",
        "            self.train_loss.append(logs['loss'])\n",
        "        if logs.get('eval_loss') is not None:\n",
        "            self.eval_loss.append(logs['eval_loss'])\n",
        "        if logs.get('eval_accuracy') is not None:\n",
        "            self.eval_acc.append(logs['eval_accuracy'])\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.train_loss, label='Train Loss')\n",
        "        plt.plot(self.eval_loss, label='Validation Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Logging Step')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.eval_acc, label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "custom_callback = CustomCallback()\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    report = classification_report(labels, preds, output_dict=True)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision_0\": report['0']['precision'],\n",
        "        \"recall_0\": report['0']['recall'],\n",
        "        \"f1_0\": report['0']['f1-score'],\n",
        "        \"precision_1\": report['1']['precision'],\n",
        "        \"recall_1\": report['1']['recall'],\n",
        "        \"f1_1\": report['1']['f1-score']\n",
        "    }\n",
        "\n",
        "# Initialize CustomTrainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[custom_callback]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_results = trainer.evaluate(val_dataset)\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"Accuracy: {val_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {val_results['eval_precision_0']:.4f}, Recall: {val_results['eval_recall_0']:.4f}, F1: {val_results['eval_f1_0']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {val_results['eval_precision_1']:.4f}, Recall: {val_results['eval_recall_1']:.4f}, F1: {val_results['eval_f1_1']:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {test_results['eval_precision_0']:.4f}, Recall: {test_results['eval_recall_0']:.4f}, F1: {test_results['eval_f1_0']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {test_results['eval_precision_1']:.4f}, Recall: {test_results['eval_recall_1']:.4f}, F1: {test_results['eval_f1_1']:.4f}\")\n",
        "\n",
        "# Plot loss and accuracy\n",
        "custom_callback.plot_metrics()\n",
        "\n",
        "# Generate predictions for confusion matrix on test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "pred_labels = predictions.predictions.argmax(-1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "# Print prediction distribution\n",
        "print(\"\\nPrediction Distribution on Test Set:\")\n",
        "print(pd.Series(pred_labels).value_counts())\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud (0)', 'Fraud (1)'], yticklabels=['Not Fraud (0)', 'Fraud (1)'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Bangla BERT Classification')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(true_labels, pred_labels, target_names=['Not Fraud (0)', 'Fraud (1)']))"
      ],
      "metadata": {
        "id": "wjQ063ZXsKHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, Bidirectional, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Enable mixed precision training\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Minimal Bengali stopword list\n",
        "bengali_stopwords = [\n",
        "    'এ', 'ও', 'তা', 'তাই', 'তার', 'তিনি', 'তুমি', 'তো', 'থেকে', 'দিয়ে', 'না', 'নেই', 'যে', 'যা', 'যার',\n",
        "    'যিনি', 'যদি', 'যখন', 'কি', 'কিন্তু', 'কারণ', 'এবং', 'অথবা', 'হয়', 'হতে', 'হয়েছে', 'আমি', 'আমার'\n",
        "]\n",
        "\n",
        "# Assume train_df, val_df, test_df, augmented_train_df are predefined\n",
        "# If not, uncomment the following to load and split dataset\n",
        "\"\"\"\n",
        "df = pd.read_csv(\"/content/combined_data.csv\", usecols=[\"Text\", \"Fraud level\"])\n",
        "df = df[df['Fraud level'].isin([0, 1])]\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df[\"Fraud level\"])\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"Fraud level\"])\n",
        "augmented_train_df = train_df.copy()\n",
        "\"\"\"\n",
        "\n",
        "# Display results\n",
        "print(\"Original Training Set Size:\", len(train_df))\n",
        "print(\"Augmented Training Set Size:\", len(augmented_train_df))\n",
        "print(\"Validation Set Size:\", len(val_df))\n",
        "print(\"Test Set Size:\", len(test_df))\n",
        "print(\"\\nSample of Augmented Training Set:\\n\", augmented_train_df.head(10))\n",
        "print(\"\\nValidation Set:\\n\", val_df.head())\n",
        "print(\"\\nTest Set:\\n\", test_df.head())\n",
        "print(\"\\nUnique Fraud Levels in Training Set:\", augmented_train_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Validation Set:\", val_df['Fraud level'].unique())\n",
        "print(\"Unique Fraud Levels in Test Set:\", test_df['Fraud level'].unique())\n",
        "\n",
        "# Combine test, validation, and augmented training set for visualization\n",
        "df_combined = pd.concat([test_df, val_df, augmented_train_df])\n",
        "\n",
        "# Count fraud labels\n",
        "fraud_counts = df_combined['Fraud level'].value_counts()\n",
        "\n",
        "# Chart.js configuration for fraud label distribution\n",
        "print(\"\"\"\n",
        "```chartjs\n",
        "{\n",
        "  \"type\": \"bar\",\n",
        "  \"data\": {\n",
        "    \"labels\": [\"Not Fraud (0)\", \"Fraud (1)\"],\n",
        "    \"datasets\": [{\n",
        "      \"label\": \"Fraud Label Count\",\n",
        "      \"data\": [\"\"\" + str(fraud_counts.get(0, 0)) + \"\"\", \"\"\" + str(fraud_counts.get(1, 0)) + \"\"\"],\n",
        "      \"backgroundColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderColor\": [\"#36A2EB\", \"#FF9F40\"],\n",
        "      \"borderWidth\": 1\n",
        "    }]\n",
        "  },\n",
        "  \"options\": {\n",
        "    \"scales\": {\n",
        "      \"y\": {\n",
        "        \"beginAtZero\": true,\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Count\"\n",
        "        }\n",
        "      },\n",
        "      \"x\": {\n",
        "        \"title\": {\n",
        "          \"display\": true,\n",
        "          \"text\": \"Fraud Label\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"plugins\": {\n",
        "      \"title\": {\n",
        "        \"display\": true,\n",
        "        \"text\": \"Fraud Label Distribution in Test + Validation + Training Set\"\n",
        "      },\n",
        "      \"legend\": {\n",
        "        \"display\": false\n",
        "      }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\"\"\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset Description:\")\n",
        "print(df.describe())\n",
        "print(\"\\nFirst 5 Rows of Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Text preprocessing functions\n",
        "def replace_strings(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\u00C0-\\u017F\"\n",
        "                               u\"\\u2000-\\u206F\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    english_pattern = re.compile('[a-zA-Z0-9]+', flags=re.I)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    text = english_pattern.sub(r'', text)\n",
        "    return text\n",
        "\n",
        "def remove_punctuations(my_str):\n",
        "    punctuations = '''````£|¢|Ñ+-*/=EROero৳০১২৩৪৫৬৭৮৯012–34567•89।!()-[]{};:'\"“\\’,<>./?@#$%^&*_~‘—॥”‰⚽️✌ ￰৷￰'''\n",
        "    no_punct = \"\"\n",
        "    for char in my_str:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char\n",
        "    return no_punct\n",
        "\n",
        "def preprocessing(text):\n",
        "    text = str(text)\n",
        "    try:\n",
        "        text = normalize(text)  # Unicode normalization\n",
        "    except Exception as e:\n",
        "        print(f\"Normalization failed: {e}\")\n",
        "    text = remove_punctuations(replace_strings(text))\n",
        "    text = ' '.join([word for word in text.split() if word not in bengali_stopwords])  # Stopword removal\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize whitespace\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "augmented_train_df['Text'] = augmented_train_df['Text'].apply(preprocessing)\n",
        "val_df['Text'] = val_df['Text'].apply(preprocessing)\n",
        "test_df['Text'] = test_df['Text'].apply(preprocessing)\n",
        "\n",
        "# Reset indices\n",
        "augmented_train_df.reset_index(drop=True, inplace=True)\n",
        "val_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Prepare training, validation, and testing data\n",
        "train_texts = augmented_train_df['Text'].values\n",
        "train_labels = augmented_train_df['Fraud level'].values.astype(int)\n",
        "val_texts = val_df['Text'].values\n",
        "val_labels = val_df['Fraud level'].values.astype(int)\n",
        "test_texts = test_df['Text'].values\n",
        "test_labels = test_df['Fraud level'].values.astype(int)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Tokenize data\n",
        "vocab_size = 25000\n",
        "embedding_dim = 300\n",
        "max_length = 100\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# One-hot encode labels\n",
        "train_labels_cat = to_categorical(train_labels)\n",
        "val_labels_cat = to_categorical(val_labels)\n",
        "test_labels_cat = to_categorical(test_labels)\n",
        "\n",
        "# LSTM+CNN Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "model.add(Conv1D(256, kernel_size=3, activation=\"relu\"))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(Conv1D(512, kernel_size=3, activation=\"relu\"))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile with categorical crossentropy\n",
        "adam = Adam(learning_rate=0.00005, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "# Build model\n",
        "model.build(input_shape=(None, max_length))\n",
        "model.summary()\n",
        "\n",
        "# Custom callback to log metrics and compute F1-score\n",
        "class CustomCallback(Callback):\n",
        "    def __init__(self, validation_data, test_data):\n",
        "        super().__init__()\n",
        "        self.val_data = validation_data\n",
        "        self.test_data = test_data\n",
        "        self.train_loss = []\n",
        "        self.eval_loss = []\n",
        "        self.eval_acc = []\n",
        "        self.eval_f1 = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_x, val_y = self.val_data\n",
        "        val_y_binary = np.argmax(val_y, axis=1)\n",
        "        val_pred = self.model.predict(val_x, verbose=0)\n",
        "        val_pred_binary = np.argmax(val_pred, axis=1)\n",
        "        val_f1 = f1_score(val_y_binary, val_pred_binary, labels=[1], average='binary')\n",
        "\n",
        "        self.train_loss.append(logs.get('loss'))\n",
        "        self.eval_loss.append(logs.get('val_loss'))\n",
        "        self.eval_acc.append(logs.get('val_accuracy'))\n",
        "        self.eval_f1.append(val_f1)\n",
        "        print(f\"Epoch {epoch+1}: Validation F1 (Fraud) = {val_f1:.4f}\")\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(self.train_loss, label='Train Loss')\n",
        "        plt.plot(self.eval_loss, label='Validation Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(self.eval_acc, label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.plot(self.eval_f1, label='Validation F1 (Fraud)')\n",
        "        plt.title('F1-Score (Fraud Class)')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('F1-Score')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Early stopping based on F1-score\n",
        "early_stopping = EarlyStopping(monitor='val_f1', mode='max', patience=3, restore_best_weights=True, verbose=1)\n",
        "\n",
        "custom_callback = CustomCallback(validation_data=(val_padded, val_labels_cat), test_data=(test_padded, test_labels_cat))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_padded,\n",
        "    train_labels_cat,\n",
        "    epochs=30,\n",
        "    batch_size=30,\n",
        "    validation_data=(val_padded, val_labels_cat),\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stopping, custom_callback]\n",
        ")\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_loss, val_acc = model.evaluate(val_padded, val_labels_cat, verbose=0)\n",
        "val_pred = model.predict(val_padded, verbose=0)\n",
        "val_pred_binary = np.argmax(val_pred, axis=1)\n",
        "val_true_binary = np.argmax(val_labels_cat, axis=1)\n",
        "val_report = classification_report(val_true_binary, val_pred_binary, output_dict=True)\n",
        "\n",
        "print(\"\\nValidation Metrics:\")\n",
        "print(f\"Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {val_report['0']['precision']:.4f}, Recall: {val_report['0']['recall']:.4f}, F1: {val_report['0']['f1-score']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {val_report['1']['precision']:.4f}, Recall: {val_report['1']['recall']:.4f}, F1: {val_report['1']['f1-score']:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(test_padded, test_labels_cat, verbose=0)\n",
        "test_pred = model.predict(test_padded, verbose=0)\n",
        "test_pred_binary = np.argmax(test_pred, axis=1)\n",
        "test_true_binary = np.argmax(test_labels_cat, axis=1)\n",
        "test_report = classification_report(test_true_binary, test_pred_binary, output_dict=True)\n",
        "\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(f\"Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Non-Fraud (0) - Precision: {test_report['0']['precision']:.4f}, Recall: {test_report['0']['recall']:.4f}, F1: {test_report['0']['f1-score']:.4f}\")\n",
        "print(f\"Fraud (1) - Precision: {test_report['1']['precision']:.4f}, Recall: {test_report['1']['recall']:.4f}, F1: {test_report['1']['f1-score']:.4f}\")\n",
        "\n",
        "# Plot loss and accuracy\n",
        "custom_callback.plot_metrics()\n",
        "\n",
        "# Generate predictions for confusion matrix on test set\n",
        "predictions = test_pred_binary\n",
        "true_labels = test_true_binary\n",
        "\n",
        "# Print prediction distribution\n",
        "print(\"\\nPrediction Distribution on Test Set:\")\n",
        "print(pd.Series(predictions).value_counts())\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud (0)', 'Fraud (1)'], yticklabels=['Not Fraud (0)', 'Fraud (1)'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for LSTM+CNN Classification')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(true_labels, predictions, target_names=['Not Fraud (0)', 'Fraud (1)']))"
      ],
      "metadata": {
        "id": "XhGjlhkbzP8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}